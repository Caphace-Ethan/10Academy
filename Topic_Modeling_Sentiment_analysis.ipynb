{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f611b6",
   "metadata": {},
   "source": [
    "# Project: Topic Modeling and Sentiment Analysis on Twitter Data\n",
    "\n",
    "## **Objective **\n",
    "### Social Media Tweet Analysis on Twitter Dataset\n",
    "*   Topic Modeling on Twitter Dataset\n",
    "*   Sentiment analysis on Twitter Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f4b39",
   "metadata": {},
   "source": [
    "### **Topic modeling**\n",
    "Topic modeling is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of texts.\n",
    "\n",
    "\n",
    "*   The task here is to discover abstract topics from tweets.\n",
    "\n",
    "\n",
    "### **Sentiment analysis**\n",
    " It is used in social media monitoring, allowing businesses to gain insights about how customers feel about certain topics, and detect urgent issues in real time before they spiral out of control.\n",
    "\n",
    "\n",
    "*   The task here is to classify a tweet as a positive or negative tweet sentiment wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820546f8",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "### Loading necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95f762a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import STOPWORDS,WordCloud\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2f4c414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_file: str)->list:\n",
    "    \"\"\"\n",
    "    json file reader to open and read json files into a list\n",
    "    Args:\n",
    "    -----\n",
    "    json_file: str - path of a json file\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    length of the json file and a list of json\n",
    "    \"\"\"\n",
    "    \n",
    "    tweets_data = []\n",
    "    for tweets in open(json_file,'r'):\n",
    "        tweets_data.append(json.loads(tweets))\n",
    "    \n",
    "    return len(tweets_data), tweets_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a09462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Successfully Saved.!!!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>original_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thu Jun 17 16:18:28 +0000 2021</td>\n",
       "      <td>ðŸš¨Africa is \"in the midst of a full-blown third...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Jun 18 16:40:24 +0000 2021</td>\n",
       "      <td>Dr Moeti is head of WHO in Africa, and one of ...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Jun 18 17:45:27 +0000 2021</td>\n",
       "      <td>Thank you @research2note for creating this ama...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Jun 16 00:21:22 +0000 2021</td>\n",
       "      <td>Former Pfizer VP and Virologist, Dr. Michael Y...</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Jun 18 13:34:47 +0000 2021</td>\n",
       "      <td>I think itâ€™s important that we donâ€™t sell COVA...</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Thu Jun 17 16:18:28 +0000 2021   \n",
       "1  Fri Jun 18 16:40:24 +0000 2021   \n",
       "2  Fri Jun 18 17:45:27 +0000 2021   \n",
       "3  Wed Jun 16 00:21:22 +0000 2021   \n",
       "4  Fri Jun 18 13:34:47 +0000 2021   \n",
       "\n",
       "                                       original_text lang possibly_sensitive  \n",
       "0  ðŸš¨Africa is \"in the midst of a full-blown third...   en              False  \n",
       "1  Dr Moeti is head of WHO in Africa, and one of ...   en              False  \n",
       "2  Thank you @research2note for creating this ama...   en               None  \n",
       "3  Former Pfizer VP and Virologist, Dr. Michael Y...   en              False  \n",
       "4  I think itâ€™s important that we donâ€™t sell COVA...   en               None  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TweetDfExtractor:\n",
    "    \"\"\"\n",
    "    this function will parse tweets json into a pandas dataframe\n",
    "    \n",
    "    Return\n",
    "    #------\n",
    "    dataframe\n",
    "    \"\"\"\n",
    "    def __init__(self, tweets_list):\n",
    "        \n",
    "        self.tweets_list = tweets_list\n",
    "\n",
    "        \n",
    "    def find_full_text(self)->list:\n",
    "        text = []\n",
    "        for element in self.tweets_list:\n",
    "            if 'retweeted_status' in element:\n",
    "                if 'extended_tweet' in element['retweeted_status']:\n",
    "                    text.append(element['retweeted_status']['extended_tweet']['full_text'])\n",
    "                else:\n",
    "                    text.append(element['retweeted_status']['text'])\n",
    "            else:\n",
    "                try:\n",
    "\n",
    "                    if 'extended_tweet' in element['quoted_status']:\n",
    "                        text.append(element['quoted_status']['extended_tweet']['full_text'])\n",
    "                    else:\n",
    "                        text.append(element['quoted_status']['text'])\n",
    "                except:\n",
    "                    text.append(element['text'])\n",
    "\n",
    "\n",
    "        return text\n",
    "    \n",
    "\n",
    "    def find_created_time(self)->list:\n",
    "        created_at = [] # Initialize empty list\n",
    "        for element in self.tweets_list:\n",
    "            if 'retweeted_status' in element:\n",
    "                created_at.append(element['retweeted_status']['created_at'])\n",
    "                    \n",
    "            else:\n",
    "                created_at.append(element['created_at'])\n",
    "\n",
    "        return created_at\n",
    "\n",
    "    \n",
    "\n",
    "    def is_sensitive(self)->list:\n",
    "        is_sensitive = []\n",
    "        for element in self.tweets_list:\n",
    "            if 'retweeted_status' in element:\n",
    "                try:\n",
    "                    is_sensitive.append(element['retweeted_status']['possibly_sensitive'])\n",
    "                except:\n",
    "                    is_sensit = None\n",
    "                    is_sensitive.append(is_sensit)\n",
    "            else:\n",
    "                is_sensit = None\n",
    "                is_sensitive.append(is_sensit)\n",
    "\n",
    "        return is_sensitive\n",
    "\n",
    "    \n",
    "\n",
    "    def find_lang(self)->list:\n",
    "        lang = []\n",
    "        for element in self.tweets_list:\n",
    "            if 'lang' in element:\n",
    "                lang.append(element['lang'])\n",
    "                    \n",
    "            else:\n",
    "                lang = None\n",
    "                \n",
    "        return lang\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "    def get_tweet_df(self, save=False)->pd.DataFrame:\n",
    "        \"\"\"required column to be generated you should be creative and add more features\"\"\"\n",
    "        \n",
    "        columns = ['created_at', 'original_text', 'lang','possibly_sensitive']\n",
    "        \n",
    "        created_at = self.find_created_time()\n",
    "#         print(len(created_at))\n",
    "        text = self.find_full_text()\n",
    "#         print(len(text))\n",
    "        lang = self.find_lang()\n",
    "#         print(len(lang))\n",
    "        sensitivity = self.is_sensitive()\n",
    "#         print(len(sensitivity))\n",
    "        data = zip(created_at, text, lang, sensitivity)\n",
    "\n",
    "        df = pd.DataFrame(data=data, columns=columns)\n",
    "        if True:\n",
    "            df.to_csv('processed_tweet_data.csv', index=False)\n",
    "            print('File Successfully Saved.!!!')\n",
    "        \n",
    "        return df\n",
    "\n",
    "                \n",
    "\n",
    "# required column to be generated you should be creative and add more features\n",
    "columns = ['created_at', 'original_text','clean_text', 'sentiment','polarity','subjectivity', 'lang','possibly_sensitive']\n",
    "tweet_len, tweet_list = read_json(\"data/covid19.json\")\n",
    "tweet_list[:1]\n",
    "tweet = TweetDfExtractor(tweet_list)\n",
    "tweet_df = tweet.get_tweet_df() \n",
    "tweet_df.head()\n",
    "# use all defined functions to generate a dataframe with the specified columns above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e919eb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c707153a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2c5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
